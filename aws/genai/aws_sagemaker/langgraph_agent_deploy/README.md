# LangGraph S3 Processing Agent ğŸš€

Process text files from S3 using LangGraph and OpenRouter LLMs, then save results back to S3.

## ğŸ¯ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Set OpenRouter API Key
Get your free API key from [https://openrouter.ai/keys](https://openrouter.ai/keys)

```bash
# Windows
set OPENROUTER_API_KEY=your-key-here

# Linux/Mac
export OPENROUTER_API_KEY=your-key-here
```

### 3. Run Locally
```bash
python test_locally.py
```

## ğŸ“‹ What It Does

1. **Reads** `input/input.txt` from S3 bucket `my-langgraph-bedrock-agent`
2. **Processes** text using Claude 3.5 Sonnet via OpenRouter
3. **Writes** summary to `output/output.txt` in the same S3 bucket

## ğŸ“ Project Structure

```
langgraph_agent_deploy/
â”œâ”€â”€ agent_graph.py              # Main LangGraph workflow
â”œâ”€â”€ app.py                      # FastAPI server
â”œâ”€â”€ test_locally.py             # Local testing script
â”œâ”€â”€ Dockerfile                  # Container definition
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ deploy_to_sagemaker.py      # SageMaker deployment
â”œâ”€â”€ build_and_push.sh           # ECR build script
â”œâ”€â”€ DEPLOYMENT_GUIDE.md         # Full deployment guide
â”œâ”€â”€ OPENROUTER_SETUP.md         # OpenRouter setup guide
â””â”€â”€ README.md                   # This file
```

## ğŸ³ Docker Deployment

### Build & Run Locally
```bash
docker build -t langgraph-agent:latest .
docker run -p 8080:8080 \
  -e OPENROUTER_API_KEY=$OPENROUTER_API_KEY \
  -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
  langgraph-agent:latest
```

### Test Container
```bash
curl -X POST http://localhost:8080/invoke \
  -H "Content-Type: application/json" \
  -d '{
    "bucket": "my-langgraph-bedrock-agent",
    "input_key": "input/input.txt",
    "output_key": "output/output.txt"
  }'
```

## â˜ï¸ SageMaker Deployment

### 1. Build & Push to ECR
```bash
./build_and_push.sh
```

### 2. Deploy to SageMaker
```bash
python deploy_to_sagemaker.py
```

See [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) for detailed instructions.

## ğŸ”‘ Configuration

### Environment Variables
- `OPENROUTER_API_KEY` - Your OpenRouter API key (required)
- `AWS_REGION` - AWS region (default: us-east-1)
- `AWS_ACCESS_KEY_ID` - AWS credentials (optional if using IAM role)
- `AWS_SECRET_ACCESS_KEY` - AWS credentials (optional if using IAM role)

### Change LLM Model
Edit [agent_graph.py](agent_graph.py) line 49:

```python
"model": "anthropic/claude-3.5-sonnet",  # Change this
```

**Free models:**
- `meta-llama/llama-3.1-8b-instruct:free`
- `google/gemma-2-9b-it:free`

See all models: https://openrouter.ai/models

## ğŸ“š Documentation

- **[OPENROUTER_SETUP.md](OPENROUTER_SETUP.md)** - OpenRouter configuration and troubleshooting
- **[DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md)** - Complete deployment guide for AWS

## ğŸ› Troubleshooting

### API Key Not Set
```
âš ï¸  WARNING: OPENROUTER_API_KEY not set!
```
**Fix:** Set the environment variable as shown in Quick Start

### S3 Access Denied
**Fix:** Ensure your AWS credentials have S3 read/write permissions

### OpenRouter Rate Limit
**Fix:** Wait or upgrade to paid tier at https://openrouter.ai

## ğŸ’° Cost Estimate

- **OpenRouter (Claude 3.5)**: ~$3-15 per 1M tokens
- **S3**: $0.023 per GB/month + requests
- **SageMaker (ml.m5.xlarge)**: ~$0.23/hour

**Free tier available** for testing with free models!

## ğŸ“ Learn More

- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)
- [OpenRouter Docs](https://openrouter.ai/docs)
- [AWS SageMaker Docs](https://docs.aws.amazon.com/sagemaker/)

## ğŸ“ License

MIT

---

**Need help?** Check [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) or [OPENROUTER_SETUP.md](OPENROUTER_SETUP.md)
